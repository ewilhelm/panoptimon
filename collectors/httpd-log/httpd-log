#!/usr/bin/env ruby

require 'json'
require 'timeout'

defaults = {
  timeout: 70,
  interval: 60,
  report_path: '/',
  report_periods: ['15m', '1h', '1d'],
  state_file: '/var/run/panoptimon/httpd-log-state.json',
}

# put_1d: 1800, max_put_1d: 600, _data: {user_stats: { bob: {put_1d: 600, ...}}}

ARGV[0] or fail "arguments required"
conf = defaults.merge(JSON.parse(ARGV[0], {symbolize_names: true}))
warn "timeout: #{conf[:timeout]}"

fail "must have 'file' value in config" unless conf[:file]
fail "timeout too short" if conf[:timeout] <= 3

parse = ->() {
  matcher = Regexp.new(
    (['([^ ]+)'] * 3 + [
    '\[([^\]]+)\]', # date
     '"([^ ]+)', # method
     '([^ ]+)',  # path
     '([^ ]+)"', # type
     '(\d+)', '(\d+)']).join(' '))
  fields = Hash[->(){n=0;
    %w(host ident user date method path type code size).map {|x| [x,n+=1]}
  }[]]
  ->(line) {
    m = matcher.match(line)
    d = Hash[fields.keys.map {|k| [k,m[fields[k]]]}]
    return d
  }
}[]

# Just kill the tail process and restart so we'll keep tail honest and
# also report before our configured timeout.
# NOTE: ignoring the parsed date, assume it happened now.  Should be
# true because we start tail with zero lines of output.  This might be a
# problem where requests sneak past at restart on very lightly loaded
# nodes.
while(true) do
  p = IO.popen(['tail', '-n','0', '-F', conf[:file]], 'r')
  begin
    while(true) do
      d = ::Timeout::timeout(2) { parse[p.readline] } or break
    end
  rescue Timeout::Error
    puts "{}"
    next
  end
end
